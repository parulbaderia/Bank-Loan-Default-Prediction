{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import warnings \n",
    "warnings.simplefilter(\"ignore\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn as skl\n",
    "import imblearn as im\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing training data and test data\n",
    "\n",
    "df_train = pd.read_csv('credit_train.csv')\n",
    "df_test = pd.read_csv('credit_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting information about the training data\n",
    "df_train.info()\n",
    "df_train.isnull().sum()\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary = pd.DataFrame(df_train.describe())\n",
    "Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(13,8)})\n",
    "sns.heatmap(df_train.corr(),annot=True, linewidths=1, annot_kws={\"size\":11})\n",
    "plt.pyplot.title('Correlation Heatmap')\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Histogram of Years of credit history vs Customer Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.hist(column='Years of Credit History', bins=25, grid=False, figsize=(10,6), edgecolor = 'k')\n",
    "plt.pyplot.xlabel('Years of Credit History')\n",
    "plt.pyplot.ylabel('Customer Count')\n",
    "plt.pyplot.title('Customer Count vs Years of Credit History ')\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The above graph is normally distributed with outliers greater than 50 years of credit history , \n",
    "#therefore we removed values >50 in year of credit history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Box Plot of Current Loan Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Current Loan Amount'].plot(kind='box', title='Loan Amount')\n",
    "#plt.pyplot.ylim(0,1)\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed outlier of current loan amount = 99999999.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stacked bar chart of Loan Status for years in current job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('Years in current job')['Loan Status'].value_counts().unstack(level=1).plot.bar(stacked=True)\n",
    "plt.pyplot.ylabel('Customer Count')\n",
    "plt.pyplot.title('Number of Customers vs Years in current job')\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is similar Loan status proportion amongst all the Years in current job "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bar Chart of Loan Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(5,3)})\n",
    "sns.countplot(data=df_train, x='Loan Status', palette='turbo').set(title='Customer count vs Loan Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Loan Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The decision variable which is loan status has majority of data inclined towards \"Fully paid\" category which inturn would result in overfitting of data ,\n",
    "# to resolve this issue , we performed resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataCleaning(df):\n",
    "        ##Filtering out outlier data for credit score using Boolean Mask\n",
    "        mask = df['Credit Score'] <=850\n",
    "        df = df[mask]\n",
    "\n",
    "        ##Filtering out value of Current Loan Amount that is not equal to 99999999.0\n",
    "        df = df[df['Current Loan Amount'] != 99999999.0]\n",
    "\n",
    "        ##Filtering out outlier data for Years of Credit History using Boolean Mask\n",
    "\n",
    "        df = df[df['Years of Credit History'] <=50]\n",
    "\n",
    "        ##Filtering null values \n",
    "        #df['Bankruptcies'].dropna(inplace=True)\n",
    "        #df['Years in current job'].dropna(inplace=True)\n",
    "\n",
    "        ##Adding null values with zero\n",
    "        df['Years in current job'].fillna(0,inplace=True)\n",
    "\n",
    "        ##Removing redundant columns\n",
    "        df.drop(columns=['Loan ID','Customer ID'],inplace=True)\n",
    "        df.drop(columns='Months since last delinquent',inplace=True)\n",
    "\n",
    "        ##Filtering out values of Years in current job that is not equal to 0\n",
    "        df = df[df['Years in current job'] != 0]\n",
    "\n",
    "        ##Adding null values of Bankruptcies column with 10 for subsequent filtering\n",
    "        df['Bankruptcies'].fillna(10,inplace=True)\n",
    "\n",
    "         ##Filtering out values of Bankruptcies that is not equal to 10\n",
    "        df = df[df['Bankruptcies'] != 10]\n",
    "\n",
    "        ##Encoding values of Term, Years in current job, Purpose, Home Ownership\n",
    "        df['Term'].replace(to_replace=['Short Term', 'Long Term'], value=[1,0],inplace=True)\n",
    "        df['Years in current job'].replace(to_replace=['8 years', '3 years', '< 1 year', '2 years', '10+ years',\n",
    "       '4 years', '5 years', '1 year', '7 years', '6 years', '9 years'], value=[1,2,3,4,5,6,7,8,9,10,11],inplace=True)\n",
    "        df['Home Ownership'].replace(to_replace=['Home Mortgage', 'Own Home', 'Rent', 'HaveMortgage'], value=[1,2,3,4],inplace=True)\n",
    "        df['Purpose'].replace(to_replace=['Home Improvements', 'Debt Consolidation', 'Buy House', 'other',\n",
    "       'Take a Trip', 'Other', 'Business Loan', 'Buy a Car',\n",
    "       'small_business', 'Medical Bills', 'vacation',\n",
    "       'Educational Expenses', 'wedding', 'major_purchase', 'moving',\n",
    "       'renewable_energy'], value=[1,2,3,4,5,4,6,7,8,9,10,11,12,13,14,15],inplace=True)\n",
    "\n",
    "        ##Replacing column header names\n",
    "        df.columns = df.columns.str.replace(' ', '_')\n",
    "        return df\n",
    "\n",
    "\n",
    "#####TRAINING DATA#####\n",
    "##Encoding Loan Status Categorical variable with 0 and 1\n",
    "df_train['Loan Status'] = df_train['Loan Status'].replace(to_replace=['Fully Paid','Charged Off'],value=[1,0])\n",
    "\n",
    "df_train = DataCleaning(df_train)\n",
    "df_train\n",
    "\n",
    "####TEST DATA#####\n",
    "df_test = DataCleaning(df_test)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation Plot post cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15,8)})\n",
    "sns.heatmap(df_train.corr(),annot=True, linewidths=1, annot_kws={\"size\":11})\n",
    "plt.pyplot.title('Correlation Heatmap')\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating X and y variable where X is the independent variable and y is the dependent variable\n",
    "X = df_train[['Current_Loan_Amount', 'Term', 'Credit_Score',\n",
    "       'Annual_Income', 'Years_in_current_job', 'Home_Ownership', 'Purpose',\n",
    "       'Monthly_Debt', 'Years_of_Credit_History', 'Number_of_Open_Accounts',\n",
    "       'Number_of_Credit_Problems', 'Current_Credit_Balance',\n",
    "       'Maximum_Open_Credit', 'Bankruptcies', 'Tax_Liens']]\n",
    "y = df_train['Loan_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating object for LogisticRegression()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "#Using train_test_split to partition the data into train and test.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model Fitting\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_accuracy_score = skl.metrics.accuracy_score(y_test,y_pred)\n",
    "prob_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision variable Loan Status count before data resampling\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using RandomOverSampler we are trying to resolve over sampling by adding duplicate rows from minority class in the data.\n",
    "over_sampling = im.over_sampling.RandomOverSampler(sampling_strategy=0.7)\n",
    "X_over_sampling, y_over_sampling = over_sampling.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision variable Loan Status count after data resampling\n",
    "y_over_sampling.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_over_sampling.shape)\n",
    "print(y_over_sampling.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_over_sampling,y_over_sampling)\n",
    "y_pred_over = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred_over, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_accuracy_score_over = skl.metrics.accuracy_score(y_test,y_pred_over)\n",
    "prob_accuracy_score_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the loan status outcome on new dataset for recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "recom = logreg.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "recom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding loan status predicted values as a column in the existing data\n",
    "df_test.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_recom = pd.DataFrame(recom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Logistic_final=pd.concat([df_test, df_prediction_recom], axis=1)\n",
    "df_Logistic_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Logistic_final.rename(columns={0:'Loan Status Predicted'},inplace=True)\n",
    "df_Logistic_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Logistic_final['Loan Status Predicted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding loan status name column for making piechart\n",
    "df_Logistic_final['Loan_Status_Name'] = np.where(df_Logistic_final['Loan Status Predicted'] == 1, \"Fully Paid\", \"Charged off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quality check\n",
    "df_Logistic_final['Loan_Status_Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pie chart of the predicted values (% split)\n",
    "df_Logistic_final.groupby('Loan_Status_Name').count().plot(kind='pie',y='Loan Status Predicted',autopct='%1.0f%%',\n",
    "                                                           title='Loan Status Share',radius = 0.8)\n",
    "plt.pyplot.ylabel(\"\")\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=4)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "dt.fit(X_over_sampling, y_over_sampling)\n",
    "\n",
    "# making predictions\n",
    "\n",
    "prediction = dt.predict(X_over_sampling)\n",
    "print('Prediction {}'.format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_over_names = ['Fully Paid','Charged Off' ]\n",
    "X_over_names = list(X_over_sampling.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pyplot.figure(figsize=(30, 20))\n",
    "plot_tree(dt, filled=True, fontsize=12, feature_names=X_over_names, \n",
    "          rounded=True, class_names = y_over_names)\n",
    "plt.pyplot.title(\"Decision tree of the iris dataset\")\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_dec, X_test_dec, y_train_dec, y_test_dec =train_test_split(X_over_sampling, y_over_sampling, test_size=0.3,random_state=21, stratify=y_over_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=20)\n",
    "test = dt.fit(X_train_dec, y_train_dec)\n",
    "y_pred = dt.predict(X_test_dec)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))\n",
    "dt.score(X_test_dec, y_test_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_decision_tree = dt.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_decision_tree.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_decision_tree = pd.DataFrame(prediction_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DecisionTree_Final=pd.concat([df_test, df_prediction_decision_tree], axis=1)\n",
    "df_DecisionTree_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DecisionTree_Final.rename(columns={0:'Loan Status Predicted'},inplace=True)\n",
    "df_DecisionTree_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing cols to check the output % match of logistic regression output and decision tree output\n",
    "output_comparison = recom==prediction_decision_tree\n",
    "output_comparison_Series= pd.Series(output_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_comparison_Series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage of matched output\n",
    "output_comparison_Series.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Logistic_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_Logistic_final.describe()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_charged_off = df_Logistic_final[df_Logistic_final['Loan Status Predicted'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [705033, 955033, 1205033, 1455033, 1705033, 1955033, 2205033, 2455033, 2705033, 2955033]\n",
    "plt.pyplot.hist(df_charged_off[\"Annual_Income\"], bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_charged_off[\"Annual_Income\"].hist(bins=int)\n",
    "\n",
    "# plt.hist(df_charged_off[\"Annual_Income\"], bins=10)\n",
    "\n",
    "w=100000\n",
    "\n",
    "plt.pyplot.hist(df_charged_off[\"Annual_Income\"], bins=np.arange(min(df_charged_off[\"Annual_Income\"]), max(df_charged_off[\"Annual_Income\"]) + w, w))\n",
    "#plt.xticks(rotation =0)\n",
    "plt.pyplot.ticklabel_format(style='plain')\n",
    "plt.pyplot.title('Charged off distribution')\n",
    "plt.pyplot.xlabel('Annual Income')\n",
    "plt.pyplot.ylabel('Number of Charged off Customers')\n",
    "plt.pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w=10\n",
    "\n",
    "plt.pyplot.hist(df_charged_off[\"Credit_Score\"], bins=np.arange(min(df_charged_off[\"Credit_Score\"]), max(df_charged_off[\"Credit_Score\"]) + w, w))\n",
    "#plt.xticks(rotation =0)\n",
    "plt.pyplot.ticklabel_format(style='plain')\n",
    "plt.pyplot.title('Charged off distribution by Credit Score')\n",
    "plt.pyplot.xlabel('Credit Score')\n",
    "plt.pyplot.ylabel('Number of Charged off Customers')\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(df_DecisionTree_Final, x=\"Credit_Score\", title=\"Customers distribution by Credit Score\", \n",
    "                   color=\"Loan Status Predicted\",\n",
    "                  color_discrete_sequence=['indianred','blue'])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "##updating the legend names\n",
    "newnames = {'1.0':'Fully paid', '0.0': 'Charged off'}\n",
    "fig.for_each_trace(lambda t: t.update(name = newnames[t.name],\n",
    "                                      legendgroup = newnames[t.name],\n",
    "                                      hovertemplate = t.hovertemplate.replace(t.name, newnames[t.name])\n",
    "                                     )\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig1 = px.histogram(df_Logistic_final, x=\"Credit_Score\",\n",
    "                   title=\"Charged off Customers distribution by Credit Score\",\n",
    "                   color=\"Loan Status Predicted\",\n",
    "                  color_discrete_sequence=['indianred','blue'])\n",
    "\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "##updating the legend names\n",
    "newnames = {'1.0':'Fully paid', '0.0': 'Charged off'}\n",
    "fig1.for_each_trace(lambda t: t.update(name = newnames[t.name],\n",
    "                                      legendgroup = newnames[t.name],\n",
    "                                      hovertemplate = t.hovertemplate.replace(t.name, newnames[t.name])\n",
    "                                     )\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(X_train_dec, y_train_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_knn = knn.predict(X_test_dec)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_knn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_knn_df = pd.DataFrame(prediction_knn)\n",
    "y_train_dec_df = pd.DataFrame(y_test_dec)\n",
    "# prediction_knn = prediction_knn.reshape(-1,1)\n",
    "# y_test_dec = y_test_dec.reshape(-1,1)\n",
    "prediction_knn_df.shape\n",
    "#y_train_dec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_knn = skl.metrics.accuracy_score(y_test_dec,prediction_knn_df)\n",
    "score_knn\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b4064efcc73342bd01af83a83f77341e75111bba77c0c8a910c4f538a95d901"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
